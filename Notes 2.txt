Methodology and Experimental Notes
Training Cost Constraint

To reduce unnecessary training time, the search loop enforces a hard limit:
if model FLOPs + input preprocessing cost (including MT) > 45, the model is skipped.
This ensures that only architectures that could theoretically yield net speedup are evaluated.

Dataset Generation
Scene Sampling

Each sample is generated by placing five mesh instances randomly within a 5-unit radius around the camera, each with a uniformly random rotation.
Sampling uses a time-seeded RNG to avoid deterministic bias.

With probability 1/1000, a bottom-level BVH is replaced by another randomly selected BVH to diversify geometry across scenes.

Geometric Normalization

To reduce variance due to scale, each model is normalized so that its largest bounding volume has an AABB volume between 3 and 64 cubic units.

Input Models

The initial dataset uses high-quality assets (≈60k–160k triangles per model).
Final dataset size after aggregation: ~22,000 kB.

Label Distribution & Balancing

Raw dataset statistics:

Hits: ~3%

Misses: ~97%

This severe imbalance causes trivial “always miss” solutions.

To correct this, I compute a rebalance target where:

40% of samples are hits

60% are misses

Let y be the number of hits. Solving:

0.4 * total = y
0.6 * total = hits_needed


I then randomly downsample hits to match the required proportion.
This produces a training dataset where models actually learn non-trivial structure.

Dataset Size

From the original BVH corpus:

38,764 leaves

5,681 leaf samples

408,720 triangles

Final training set is formed by 100,000 random triangle samples drawn from the full pool.

Initial Experiments (No Rotation / Raw Triangles)

Using raw features (excluding u_raw / v_raw), generalist MLPs were tested across 3,424 architecture/feature combinations (1,826 trained models).

Outcome:
The highest cull rate achieved: 1.52%
This is effectively noise-level performance; most networks simply predict “miss.”

Some score distributions show slight learning, but not enough to approach usability.

Experiment 2: Canonicalizing Ray–BVH Orientation

To partially remove rotational degrees of freedom, each BVH is pre-rotated so that the axis-aligned plane of the BVH orthogonal to the camera’s z-axis intersects the ray origin at (0,0,z).

Rationale:
This avoids computing or applying per-triangle rotation transforms at inference time—something more expensive than the MT test itself.
Instead, we:

Precompute a rotated copy of each BVH

Store the rotation

At inference time, rotate the ray direction only

This yields canonical orientation without costly runtime transforms.

Result:
Cull rate increased from 1.52% → 2.95%.

Notably:

All top-performing models contained at least one hidden layer

Score histograms show two distinct peaks, indicating real pattern learning

Some models produced small “pure miss” regions in their score distributions, suggesting possible alternative thresholding methods

Experiment 3: Ray Direction Scaling (Major Breakthrough)

A new feature was introduced:
Scaling ray_dir so its magnitude equals the distance from the triangle’s v0 to the origin.
(Equivalent precomputation on BVHs is possible and likely more correct, but deferred.)

This dramatically improved performance.

Top Cull Rates (Validation)

5.81%

5.64%

3.73%

2.78%

1.91%

(Rank 20: 0.69%)

Best Model (Under FLOPs Constraint)
Arch: n=10, L=1, H=2, flops=44
Total cost: 44
Threshold (VAL): 0.458150

VAL culled fraction: 5.81%
VAL cull accuracy:   95.52%
VAL overall acc:     45.27%
VAL hit recall:      99.35%

Features: aabb, inradius, ray_dir (scaled)


Performance increased from 1.52% → 2.95% → 5.81% through successive data canonicalizations.

New Dataset: Low-Detail Models

To test generalization, the pipeline was retargeted to low-detail models (≈300–9,000 triangles).
There are 21 such assets, and the dataset was generated using the same sampling strategy.

Dataset size: ~74,000 kB (text).

Experiments on low-detail assets are ongoing.

Summary
Stage	              Technique	                    Max Cull Rate
Baseline	          Raw orientation	              1.52%
Rotation	          Canonicalized BVH orientation	2.95%
Rotation + Scaling	Scaled ray_dir	              5.81%

While performance remains far from competitive with the MT test (which is extremely cheap), the experiments show that:

Neural models do learn patterns in triangle miss/hit structure

Careful canonicalization and geometric feature engineering significantly matter

Scaling ray_dir produced the strongest gains

Even under a strict ≤45-FLOP constraint, some architectures produce meaningful culling

The approach is still not feasible for real BVH traversal, but the experiments provide a clear negative result and a systematic exploration of why.